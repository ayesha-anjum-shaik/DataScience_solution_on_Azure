{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning with TensorFlow\n",
        "\n",
        "Classical machine learning relies on using statistics to determine relationships between features and labels, and can be very effective for creating predictive models. However, a massive growth in the availability of data coupled with advances in the computing technology required to process it has led to the emergence of new machine learning techniques that mimic the way the brain processes information in a structure called an artificial neural network.\n",
        "\n",
        "TensorFlow is a framework for creating machine learning models, including deep neural networks (DNNs). In this example, we'll use Tensorflow to create a simple neural network that classifies penguins into species based on the length and depth of their culmen (bill), their flipper length, and their body mass.\n",
        "\n",
        "> **Citation**: The penguins dataset used in the this exercise is a subset of data collected and made available by [Dr. Kristen\n",
        "Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php)\n",
        "and the [Palmer Station, Antarctica LTER](https://pal.lternet.edu/), a\n",
        "member of the [Long Term Ecological Research\n",
        "Network](https://lternet.edu/).\n",
        "\n",
        "## Explore the dataset\n",
        "\n",
        "Before we start using TensorFlow to create a model, let's load the data we need from the Palmer Islands penguins dataset, which contains observations of three different species of penguin.\n",
        "\n",
        "> **Note**: In reality, you can solve the penguin classification problem easily using classical machine learning techniques without the need for a deep learning model; but it's a useful, easy to understand dataset with which to demonstrate the principles of neural networks in this notebook."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# load the training dataset (excluding rows with null values)\r\n",
        "penguins = pd.read_csv('data/penguins.csv').dropna()\r\n",
        "\r\n",
        "# Deep Learning models work best when features are on similar scales\r\n",
        "# In a real solution, we'd implement some custom normalization for each feature, but to keep things simple\r\n",
        "# we'll just rescale the FlipperLength and BodyMass so they're on a similar scale to the bill measurements\r\n",
        "penguins['FlipperLength'] = penguins['FlipperLength']/10\r\n",
        "penguins['BodyMass'] = penguins['BodyMass']/100\r\n",
        "\r\n",
        "# The dataset is too small to be useful for deep learning\r\n",
        "# So we'll oversample it to increase its size\r\n",
        "for i in range(1,3):\r\n",
        "    penguins = penguins.append(penguins)\r\n",
        "\r\n",
        "# Display a random sample of 10 observations\r\n",
        "sample = penguins.sample(10)\r\n",
        "sample"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "     CulmenLength  CulmenDepth  FlipperLength  BodyMass  Species\n112          39.7         17.7           19.3      32.0        0\n293          58.0         17.8           18.1      37.0        2\n183          42.8         14.2           20.9      47.0        1\n114          39.6         20.7           19.1      39.0        0\n90           35.7         18.0           20.2      35.5        0\n184          45.1         14.5           20.7      50.5        1\n24           38.8         17.2           18.0      38.0        0\n239          51.3         14.2           21.8      53.0        1\n68           35.9         16.6           19.0      30.5        0\n292          50.3         20.0           19.7      33.0        2",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CulmenLength</th>\n      <th>CulmenDepth</th>\n      <th>FlipperLength</th>\n      <th>BodyMass</th>\n      <th>Species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>112</th>\n      <td>39.7</td>\n      <td>17.7</td>\n      <td>19.3</td>\n      <td>32.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>293</th>\n      <td>58.0</td>\n      <td>17.8</td>\n      <td>18.1</td>\n      <td>37.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>42.8</td>\n      <td>14.2</td>\n      <td>20.9</td>\n      <td>47.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>39.6</td>\n      <td>20.7</td>\n      <td>19.1</td>\n      <td>39.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>35.7</td>\n      <td>18.0</td>\n      <td>20.2</td>\n      <td>35.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>184</th>\n      <td>45.1</td>\n      <td>14.5</td>\n      <td>20.7</td>\n      <td>50.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>38.8</td>\n      <td>17.2</td>\n      <td>18.0</td>\n      <td>38.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>51.3</td>\n      <td>14.2</td>\n      <td>21.8</td>\n      <td>53.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>35.9</td>\n      <td>16.6</td>\n      <td>19.0</td>\n      <td>30.5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>292</th>\n      <td>50.3</td>\n      <td>20.0</td>\n      <td>19.7</td>\n      <td>33.0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1666720551204
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Species** column is the label our model will predict. Each label value represents a class of penguin species, encoded as 0, 1, or 2. The following code shows the actual species to which these class labels corrrespond."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "penguin_classes = ['Adelie', 'Gentoo', 'Chinstrap']\r\n",
        "print(sample.columns[0:5].values, 'SpeciesName')\r\n",
        "for index, row in penguins.sample(10).iterrows():\r\n",
        "    print('[',row[0], row[1], row[2],row[3], int(row[4]), ']',penguin_classes[int(row[-1])])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['CulmenLength' 'CulmenDepth' 'FlipperLength' 'BodyMass' 'Species'] SpeciesName\n[ 35.9 19.2 18.9 38.0 0 ] Adelie\n[ 48.6 16.0 23.0 58.0 1 ] Gentoo\n[ 45.4 18.7 18.8 35.25 2 ] Chinstrap\n[ 51.1 16.3 22.0 60.0 1 ] Gentoo\n[ 51.5 18.7 18.7 32.5 2 ] Chinstrap\n[ 40.6 17.2 18.7 34.75 0 ] Adelie\n[ 49.5 16.2 22.9 58.0 1 ] Gentoo\n[ 45.5 13.9 21.0 42.0 1 ] Gentoo\n[ 49.6 18.2 19.3 37.75 2 ] Chinstrap\n[ 45.2 16.4 22.3 59.5 1 ] Gentoo\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1666720555406
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As is common in a supervised learning problem, we'll split the dataset into a set of records with which to train the model, and a smaller set with which to validate the trained model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "features = ['CulmenLength','CulmenDepth','FlipperLength','BodyMass']\r\n",
        "label = 'Species'\r\n",
        "   \r\n",
        "# Split data 70%-30% into training set and test set\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(penguins[features].values,\r\n",
        "                                                    penguins[label].values,\r\n",
        "                                                    test_size=0.30,\r\n",
        "                                                    random_state=0)\r\n",
        "\r\n",
        "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\r\n",
        "print(\"Sample of features and labels:\")\r\n",
        "\r\n",
        "# Take a look at the first 25 training features and corresponding labels\r\n",
        "for n in range(0,24):\r\n",
        "    print(x_train[n], y_train[n], '(' + penguin_classes[y_train[n]] + ')')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Training Set: 957, Test Set: 411 \n\nSample of features and labels:\n[51.1 16.5 22.5 52.5] 1 (Gentoo)\n[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n[49.5 16.2 22.9 58. ] 1 (Gentoo)\n[39.3 20.6 19.  36.5] 0 (Adelie)\n[42.5 20.7 19.7 45. ] 0 (Adelie)\n[50.  15.3 22.  55.5] 1 (Gentoo)\n[50.2  18.7  19.8  37.75] 2 (Chinstrap)\n[50.7 19.7 20.3 40.5] 2 (Chinstrap)\n[49.1  14.5  21.2  46.25] 1 (Gentoo)\n[43.2 16.6 18.7 29. ] 2 (Chinstrap)\n[38.8  17.6  19.1  32.75] 0 (Adelie)\n[37.8 17.1 18.6 33. ] 0 (Adelie)\n[45.8 14.2 21.9 47. ] 1 (Gentoo)\n[43.8 13.9 20.8 43. ] 1 (Gentoo)\n[36.  17.1 18.7 37. ] 0 (Adelie)\n[43.3 13.4 20.9 44. ] 1 (Gentoo)\n[36.  18.5 18.6 31. ] 0 (Adelie)\n[41.1  19.   18.2  34.25] 0 (Adelie)\n[33.1 16.1 17.8 29. ] 0 (Adelie)\n[40.9 13.7 21.4 46.5] 1 (Gentoo)\n[45.2 17.8 19.8 39.5] 2 (Chinstrap)\n[48.4 14.6 21.3 58.5] 1 (Gentoo)\n[43.6 13.9 21.7 49. ] 1 (Gentoo)\n[38.5  17.9  19.   33.25] 0 (Adelie)\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1666720558199
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *features* are the measurements for each penguin observation, and the *label* is a numeric value that indicates the species of penguin that the observation represents (Adelie, Gentoo, or Chinstrap).\n",
        "\n",
        "## Install and import TensorFlow libraries\n",
        "\n",
        "Since we plan to use TensorFlow to create our penguin classifier, we'll need to run the following two cells to install and import the libraries we intend to use.\n",
        "\n",
        "> **Note** *Keras* is an abstraction layer over the base TensorFlow API. In most common machine learning scenarios, you can use Keras to simplify your code."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting tensorflow\n  Downloading tensorflow-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n\u001b[K     |████████████████████████████████| 578.1 MB 2.8 kB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied, skipping upgrade: astunparse>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied, skipping upgrade: setuptools in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (49.6.0)\nRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.1.2)\nCollecting libclang>=13.0.0\n  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n\u001b[K     |████████████████████████████████| 14.1 MB 40 kB/s s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio<2.0,>=1.24.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.47.0)\nCollecting tensorboard<2.11,>=2.10\n  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n\u001b[K     |████████████████████████████████| 5.9 MB 49.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.12.1)\nCollecting absl-py>=1.0.0\n  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n\u001b[K     |████████████████████████████████| 124 kB 55.1 MB/s eta 0:00:01\n\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[K     |████████████████████████████████| 1.1 MB 54.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: google-pasta>=0.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied, skipping upgrade: flatbuffers>=2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (2.0)\nRequirement already satisfied, skipping upgrade: typing-extensions>=3.6.6 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (4.3.0)\nCollecting keras<2.11,>=2.10.0\n  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n\u001b[K     |████████████████████████████████| 1.7 MB 52.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied, skipping upgrade: numpy>=1.20 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.21.6)\nRequirement already satisfied, skipping upgrade: h5py>=2.9.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (3.7.0)\nRequirement already satisfied, skipping upgrade: gast<=0.4.0,>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (0.3.3)\nRequirement already satisfied, skipping upgrade: packaging in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (21.3)\nCollecting tensorflow-io-gcs-filesystem>=0.23.1\n  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n\u001b[K     |████████████████████████████████| 2.4 MB 26.9 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n\u001b[K     |████████████████████████████████| 438 kB 29.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: wheel<1.0,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\nRequirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.28.1)\nRequirement already satisfied, skipping upgrade: werkzeug>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\nRequirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\nRequirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\nRequirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\nRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\nRequirement already satisfied, skipping upgrade: google-auth<3,>=1.6.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.9.1)\nRequirement already satisfied, skipping upgrade: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.6.15)\nRequirement already satisfied, skipping upgrade: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\nRequirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\nRequirement already satisfied, skipping upgrade: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.1.0)\nRequirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\nRequirement already satisfied, skipping upgrade: importlib-metadata>=4.4; python_version < \"3.10\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\nRequirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\nRequirement already satisfied, skipping upgrade: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\nRequirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\nRequirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.0)\nRequirement already satisfied, skipping upgrade: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\nRequirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n\u001b[31mERROR: tensorflow-gpu 2.2.0 has requirement h5py<2.11.0,>=2.10.0, but you'll have h5py 3.7.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow-gpu 2.2.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow-gpu 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.10.1 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow-gpu 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 2.10.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow-cpu 2.2.0 has requirement h5py<2.11.0,>=2.10.0, but you'll have h5py 3.7.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow-cpu 2.2.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow-cpu 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.10.1 which is incompatible.\u001b[0m\n\u001b[31mERROR: tensorflow-cpu 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 2.10.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: ray 1.13.0 has requirement grpcio<=1.43.0,>=1.28.1, but you'll have grpcio 1.47.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: autokeras 1.0.16 has requirement tensorflow<=2.5.0,>=2.3.0, but you'll have tensorflow 2.10.0 which is incompatible.\u001b[0m\nInstalling collected packages: libclang, absl-py, protobuf, tensorboard, keras, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorflow\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 0.15.0\n    Uninstalling absl-py-0.15.0:\n      Successfully uninstalled absl-py-0.15.0\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.1\n    Uninstalling protobuf-3.20.1:\n      Successfully uninstalled protobuf-3.20.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.2.2\n    Uninstalling tensorboard-2.2.2:\n      Successfully uninstalled tensorboard-2.2.2\n  Attempting uninstall: keras\n    Found existing installation: Keras 2.3.1\n    Uninstalling Keras-2.3.1:\n      Successfully uninstalled Keras-2.3.1\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.2.0\n    Uninstalling tensorflow-estimator-2.2.0:\n      Successfully uninstalled tensorflow-estimator-2.2.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.2.0\n    Uninstalling tensorflow-2.2.0:\n      Successfully uninstalled tensorflow-2.2.0\nSuccessfully installed absl-py-1.3.0 keras-2.10.0 libclang-14.0.6 protobuf-3.19.6 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0\n"
        }
      ],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras import utils\r\n",
        "from tensorflow.keras import optimizers\r\n",
        "\r\n",
        "# Set random seed for reproducability\r\n",
        "tensorflow.random.set_seed(0)\r\n",
        "\r\n",
        "print(\"Libraries imported.\")\r\n",
        "print('Keras version:',keras.__version__)\r\n",
        "print('TensorFlow version:',tensorflow.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-10-25 17:57:24.041781: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-10-25 17:57:24.268039: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2022-10-25 17:57:25.219413: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2022-10-25 17:57:25.219586: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2022-10-25 17:57:25.219604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Libraries imported.\nKeras version: 2.10.0\nTensorFlow version: 2.10.0\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1666720646571
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data for TensorFlow\n",
        "\n",
        "We've already loaded our data and split it into training and validation datasets. However, we need to do some further data preparation so that our data will work correctly with TensorFlow. Specifically, we need to set the data type of our features to 32-bit floating point numbers, and specify that the labels represent categorical classes rather than numeric values."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Set data types for float features\r\n",
        "x_train = x_train.astype('float32')\r\n",
        "x_test = x_test.astype('float32')\r\n",
        "\r\n",
        "# Set data types for categorical labels\r\n",
        "y_train = utils.to_categorical(y_train)\r\n",
        "y_test = utils.to_categorical(y_test)\r\n",
        "print('Ready...')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Ready...\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1666720647208
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a neural network\n",
        "\n",
        "Now we're ready to define our neural network. In this case, we'll create a network that consists of 3 fully-connected layers:\n",
        "* An input layer that receives an input value for each feature (in this case, the four penguin measurements) and applies a *ReLU* activation function.\n",
        "* A hidden layer that receives ten inputs and applies a *ReLU* activation function.\n",
        "* An output layer that uses a *SoftMax* activation function to generate an output for each penguin species (which represent the classification probabilities for each of the three possible penguin species). Softmax functions produce a vector with probability values that sum to 1."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a classifier network\r\n",
        "hl = 10 # Number of hidden layer nodes\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(hl, input_dim=len(features), activation='relu'))\r\n",
        "model.add(Dense(hl, input_dim=hl, activation='relu'))\r\n",
        "model.add(Dense(len(penguin_classes), input_dim=hl, activation='softmax'))\r\n",
        "\r\n",
        "print(model.summary())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 10)                50        \n                                                                 \n dense_1 (Dense)             (None, 10)                110       \n                                                                 \n dense_2 (Dense)             (None, 3)                 33        \n                                                                 \n=================================================================\nTotal params: 193\nTrainable params: 193\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1666720647313
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "To train the model, we need to repeatedly feed the training values forward through the network, use a loss function to calculate the loss, use an optimizer to backpropagate the weight and bias value adjustments, and validate the model using the test data we withheld.\n",
        "\n",
        "To do this, we'll apply an Adam optimizer to a categorical cross-entropy loss function iteratively over 50 epochs."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper-parameters for optimizer\r\n",
        "learning_rate = 0.001\r\n",
        "opt = optimizers.Adam(lr=learning_rate)\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=opt,\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "# Train the model over 50 epochs using 10-observation batches and using the test holdout dataset for validation\r\n",
        "num_epochs = 50\r\n",
        "history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_data=(x_test, y_test))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super().__init__(name, **kwargs)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/50\n96/96 [==============================] - 1s 7ms/step - loss: 4.3283 - accuracy: 0.2059 - val_loss: 1.5091 - val_accuracy: 0.1995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/50\n96/96 [==============================] - 0s 3ms/step - loss: 1.2202 - accuracy: 0.3814 - val_loss: 0.9894 - val_accuracy: 0.4891\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.8927 - accuracy: 0.5799 - val_loss: 0.7775 - val_accuracy: 0.6886\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.7259 - accuracy: 0.6792 - val_loss: 0.6598 - val_accuracy: 0.7372\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/50\n96/96 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.7304 - val_loss: 0.5922 - val_accuracy: 0.7178\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.7618 - val_loss: 0.5261 - val_accuracy: 0.8054\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.7921 - val_loss: 0.4831 - val_accuracy: 0.8224\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.8056 - val_loss: 0.4492 - val_accuracy: 0.8248\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.8109 - val_loss: 0.4253 - val_accuracy: 0.8297\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8391 - val_loss: 0.3938 - val_accuracy: 0.8467\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8276 - val_loss: 0.3833 - val_accuracy: 0.8370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8307 - val_loss: 0.3640 - val_accuracy: 0.8491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13/50\n96/96 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8474 - val_loss: 0.3413 - val_accuracy: 0.8540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8725 - val_loss: 0.3723 - val_accuracy: 0.8418\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8704 - val_loss: 0.3188 - val_accuracy: 0.8370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.2869 - accuracy: 0.8830 - val_loss: 0.2780 - val_accuracy: 0.8783\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.8945 - val_loss: 0.2566 - val_accuracy: 0.8856\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.2480 - accuracy: 0.9028 - val_loss: 0.2622 - val_accuracy: 0.8881\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.2277 - accuracy: 0.9122 - val_loss: 0.2399 - val_accuracy: 0.9075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/50\n96/96 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9195 - val_loss: 0.2295 - val_accuracy: 0.8905\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/50\n96/96 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.9216 - val_loss: 0.1957 - val_accuracy: 0.9319\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/50\n96/96 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9331 - val_loss: 0.2004 - val_accuracy: 0.9197\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9446 - val_loss: 0.1892 - val_accuracy: 0.9392\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.1555 - accuracy: 0.9582 - val_loss: 0.1497 - val_accuracy: 0.9562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/50\n96/96 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9509 - val_loss: 0.1404 - val_accuracy: 0.9586\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.9603 - val_loss: 0.1266 - val_accuracy: 0.9757\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.1236 - accuracy: 0.9666 - val_loss: 0.1195 - val_accuracy: 0.9781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9697 - val_loss: 0.1128 - val_accuracy: 0.9781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9760 - val_loss: 0.1134 - val_accuracy: 0.9708\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.1004 - accuracy: 0.9707 - val_loss: 0.1062 - val_accuracy: 0.9732\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31/50\n96/96 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9739 - val_loss: 0.0885 - val_accuracy: 0.9805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9781 - val_loss: 0.0824 - val_accuracy: 0.9781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33/50\n96/96 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.9707 - val_loss: 0.0775 - val_accuracy: 0.9854\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9801 - val_loss: 0.1066 - val_accuracy: 0.9684\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0700 - accuracy: 0.9801 - val_loss: 0.0674 - val_accuracy: 0.9781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9812 - val_loss: 0.0636 - val_accuracy: 0.9805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9822 - val_loss: 0.0562 - val_accuracy: 0.9903\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9854 - val_loss: 0.0557 - val_accuracy: 0.9976\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9843 - val_loss: 0.0668 - val_accuracy: 0.9659\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9781 - val_loss: 0.0596 - val_accuracy: 0.9781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41/50\n96/96 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9854 - val_loss: 0.0446 - val_accuracy: 0.9903\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42/50\n96/96 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9833 - val_loss: 0.0460 - val_accuracy: 0.9903\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9843 - val_loss: 0.0421 - val_accuracy: 0.9951\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9864 - val_loss: 0.0567 - val_accuracy: 0.9708\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 45/50\n96/96 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9906 - val_loss: 0.0380 - val_accuracy: 0.9903\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46/50\n96/96 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9875 - val_loss: 0.0364 - val_accuracy: 0.9927\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 0.0358 - val_accuracy: 0.9927\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9864 - val_loss: 0.0713 - val_accuracy: 0.9757\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 49/50\n96/96 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 0.9916 - val_loss: 0.0600 - val_accuracy: 0.9659\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 50/50\n96/96 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9916 - val_loss: 0.0437 - val_accuracy: 0.9854\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "scrolled": true,
        "tags": [],
        "gather": {
          "logged": 1666720668252
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the training process is running, let's try to understand what's happening:\n",
        "\n",
        "1. In each *epoch*, the full set of training data is passed forward through the network. There are four features for each observation, and four corresponding nodes in the input layer - so the features for each observation are passed as a vector of four values to that layer. However, for efficiency, the feature vectors are grouped into batches; so actually a matrix of multiple feature vectors is fed in each time.\n",
        "2. The matrix of feature values is processed by a function that performs a weighted sum using initialized weights and bias values. The result of this function is then processed by the activation function for the input layer to constrain the values passed to the nodes in the next layer.\n",
        "3. The weighted sum and activation functions are repeated in each layer. Note that the functions operate on vectors and matrices rather than individual scalar values. In other words, the forward pass is essentially a series of nested linear algebra functions. This is the reason data scientists prefer to use computers with graphical processing units (GPUs), since these are optimized for matrix and vector calculations.\n",
        "4. In the final layer of the network, the output vectors contain a probability value for each possible class (in this case, classes 0, 1, and 2). This vector is processed by a *loss function* to determine how far the values calculated by the network are from the actual values - so for example, suppose the output for a Gentoo penguin (class 1) observation is \\[0.3, 0.4, 0.3\\]. The correct prediction should be \\[0.0, 1.0, 0.0\\], so the variance between the predicted and actual values (how far away the each predicted value is from what it should be) is \\[0.3, 0.6, 0.3\\]. This variance is aggregated for each batch and maintained as a running aggregate to calculate the overall level of error (*loss*) incurred by the training data for the epoch. The accuracy (proportion of correct predictions based on the highest probability value in the output vector) for the training data is also calculated.\n",
        "5. At the end of each epoch, the validation data is passed through the network, and its loss and accuracy are also calculated. It's important to do this because it enables us to compare the performance of the model using data on which it was not trained, helping us determine if it will generalize well for new data or if it's *overfitted* to the training data.\n",
        "6. After all the data has been passed forward through the network, the output of the loss function for the *training* data (but <u>not</u> the *validation* data) is passed to the opimizer. The precise details of how the optimizer processes the loss vary depending on the specific optimization algorithm being used; but fundamentally you can think of the entire network, from the input layer to the loss function as being one big nested (*composite*) function. The optimizer applies some differential calculus to calculate *partial derivatives* for the function with respect to each weight and bias value that was used in the network. It's possible to do this efficiently for a nested function due to something called the *chain rule*, which enables you to determine the derivative of a composite function from the derivatives of its inner function and outer functions. You don't really need to worry about the details of the math here (the optimizer does it for you), but the end result is that the partial derivatives tell us about the slope (or *gradient*) of the loss function with respect to each weight and bias value - in other words, we can determine whether to increase or decrease the weight and bias values in order to decrease the loss.\n",
        "7. Having determined in which direction to adjust the weights and biases, the optimizer uses the *learning rate* to determine by how much to adjust them; and then works backwards through the network in a process called *backpropagation* to assign new values to the weights and biases in each layer.\n",
        "8. Now the next epoch repeats the whole training, validation, and backpropagation process starting with the revised weights and biases from the previous epoch - which hopefully will result in a lower level of loss.\n",
        "9. The process continues like this for 50 epochs.\n",
        "\n",
        "## Review training and validation loss\n",
        "\n",
        "After training is complete, we can examine the loss metrics we recorded while training and validating the model. We're really looking for two things:\n",
        "* The loss should reduce with each epoch, showing that the model is learning the right weights and biases to predict the correct labels.\n",
        "* The training loss and validation loss should follow a similar trend, showing that the model is not overfitting to the training data.\n",
        "\n",
        "Let's plot the loss metrics and see:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "epoch_nums = range(1,num_epochs+1)\r\n",
        "training_loss = history.history[\"loss\"]\r\n",
        "validation_loss = history.history[\"val_loss\"]\r\n",
        "plt.plot(epoch_nums, training_loss)\r\n",
        "plt.plot(epoch_nums, validation_loss)\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.legend(['training', 'validation'], loc='upper right')\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1666720669242
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View the learned weights and biases\n",
        "\n",
        "The trained model consists of the final weights and biases that were determined by the optimizer during training. Based on our network model we should expect the following values for each layer:\n",
        "* Layer 1: There are four input values going to ten output nodes, so there should be 4 x 10 weights and 10 bias values.\n",
        "* Layer 2: There are ten input values going to ten output nodes, so there should be 10 x 10 weights and 10 bias values.\n",
        "* Layer 3: There are ten input values going to three output nodes, so there should be 10 x 3 weights and 3 bias values."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\r\n",
        "    weights = layer.get_weights()[0]\r\n",
        "    biases = layer.get_weights()[1]\r\n",
        "    print('------------\\nWeights:\\n',weights,'\\nBiases:\\n', biases)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "------------\nWeights:\n [[ 0.26822883 -0.34812284  0.4746933   0.62785953 -0.10361636  0.42271125\n   0.21585906 -0.55724734 -0.5902666  -0.031941  ]\n [-0.44563803  0.19474846  1.0905957   0.25740767 -0.48193237 -0.0433126\n  -0.65989685 -0.5616509   0.6005846  -0.25663203]\n [ 0.7036974  -0.58265215 -0.1298204   0.19902666  0.33067757 -0.4203925\n  -0.0898309   0.5082059  -0.39572522  0.01046073]\n [ 0.46718225 -0.5801458  -0.19599852 -0.624366   -0.25890705 -0.15816072\n   0.46104977 -0.40293244 -0.15387851 -0.5968515 ]] \nBiases:\n [-0.00221555  0.          0.34464303 -0.13788562  0.         -0.26675054\n -0.2466965   0.          0.          0.        ]\n------------\nWeights:\n [[-0.08775738 -0.46223715 -0.4602674   0.57928365  0.5703535   0.2400884\n   0.3953489  -0.15235013 -0.0236128   0.29333746]\n [-0.21860224  0.4155333  -0.32846296  0.19126749 -0.4899248   0.1415298\n  -0.05398634  0.089764    0.31211954  0.02370417]\n [-0.34431845  0.56980056 -0.2152805  -0.41230518 -0.1674619   0.3117207\n  -0.04129503 -0.20286468  0.15720579 -0.45391765]\n [ 0.37911785  0.6336006   0.31412262 -0.11870394 -0.02074205 -0.60466313\n   0.21463244 -0.48181623  0.14580707  0.20676269]\n [-0.19422254 -0.39468193  0.12415946  0.30195516  0.17347759  0.50095177\n  -0.35457465  0.474864    0.19565141  0.41571492]\n [ 0.38656968  0.44045302  0.08991742 -0.03438367  0.07381778 -0.9984928\n  -0.4392434   0.04133219 -0.23119709 -0.24591705]\n [-0.28721553  0.35240224  0.07189482  0.1801405  -0.1797296  -0.27062112\n  -0.24399285 -0.01382357 -0.37355974  0.34718305]\n [ 0.0295105   0.1708222   0.472911   -0.3925416   0.44593704 -0.1053139\n  -0.00669169 -0.21964553 -0.43579587 -0.2777921 ]\n [-0.31409535 -0.20805186 -0.0126518   0.13132268  0.25410473  0.17673206\n   0.05867481 -0.13456896 -0.19501454 -0.3434388 ]\n [-0.3095914   0.42126948 -0.39956078 -0.2664464  -0.4318444   0.38447654\n   0.20067644  0.50424314  0.16728461 -0.3853116 ]] \nBiases:\n [ 0.         -0.0498278   0.         -0.30837336  0.00261689  0.38933268\n  0.19652657  0.          0.08732149  0.00830407]\n------------\nWeights:\n [[-5.8077085e-01  3.3012819e-01  5.6716442e-01]\n [-9.5114671e-03 -4.5511812e-01  5.8889246e-01]\n [ 2.5312400e-01 -3.8314807e-01  6.7540956e-01]\n [-3.4521985e-01  7.2453105e-01  3.8862434e-01]\n [-1.9498792e-01  5.9485596e-01 -4.5142037e-01]\n [ 6.6631901e-01 -4.4231218e-01 -7.6613474e-01]\n [ 6.2264538e-01 -3.6372206e-01  2.3187846e-01]\n [-3.6599395e-01 -6.2160504e-01 -6.2526238e-01]\n [ 6.9573647e-01 -1.4051182e+00 -5.5977756e-01]\n [-2.6101264e-04 -1.6176791e-03  2.0399173e-01]] \nBiases:\n [ 0.3279699  -0.10199974 -0.34952483]\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1666720669333
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model performance\n",
        "\n",
        "So, is the model any good? The raw accuracy reported from the validation data would seem to indicate that it predicts pretty well; but it's typically useful to dig a little deeper and compare the predictions for each possible class. A common way to visualize the performance of a classification model is to create a *confusion matrix* that shows a crosstab of correct and incorrect predictions for each class."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\r\n",
        "import numpy as np\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "\r\n",
        "class_probabilities = model.predict(x_test)\r\n",
        "predictions = np.argmax(class_probabilities, axis=1)\r\n",
        "true_labels = np.argmax(y_test, axis=1)\r\n",
        "\r\n",
        "# Plot the confusion matrix\r\n",
        "cm = confusion_matrix(true_labels, predictions)\r\n",
        "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Blues)\r\n",
        "plt.colorbar()\r\n",
        "tick_marks = np.arange(len(penguin_classes))\r\n",
        "plt.xticks(tick_marks, penguin_classes, rotation=85)\r\n",
        "plt.yticks(tick_marks, penguin_classes)\r\n",
        "plt.xlabel(\"Predicted Species\")\r\n",
        "plt.ylabel(\"Actual Species\")\r\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\r 1/13 [=>............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r13/13 [==============================] - 0s 1ms/step\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1666720669417
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The confusion matrix should show a strong diagonal line indicating that there are more correct than incorrect predictions for each class.\n",
        "\n",
        "## Save the trained model\n",
        "Now that we have a model we believe is reasonably accurate, we can save its trained weights for use later."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\r\n",
        "modelFileName = 'models/penguin-classifier.h5'\r\n",
        "model.save(modelFileName)\r\n",
        "del model  # deletes the existing model variable\r\n",
        "print('model saved as', modelFileName)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "model saved as models/penguin-classifier.h5\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1666720669496
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the trained model\n",
        "\n",
        "When we have a new penguin observation, we can use the model to predict the species."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\r\n",
        "model = models.load_model(modelFileName)\r\n",
        "\r\n",
        "# CReate a new array of features\r\n",
        "x_new = np.array([[50.4,15.3,20,50]])\r\n",
        "print ('New sample: {}'.format(x_new))\r\n",
        "\r\n",
        "# Use the model to predict the class\r\n",
        "class_probabilities = model.predict(x_new)\r\n",
        "predictions = np.argmax(class_probabilities, axis=1)\r\n",
        "\r\n",
        "print(penguin_classes[predictions[0]])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "New sample: [[50.4 15.3 20.  50. ]]\n\r1/1 [==============================] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 65ms/step\nGentoo\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1666720817197
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learn more\n",
        "\n",
        "This notebook was designed to help you understand the basic concepts and principles involved in deep neural networks, using a simple Tensorflow example. To learn more about Tensorflow, take a look at the <a href=\"https://www.tensorflow.org/\" target=\"_blank\">Tensorflow web site</a>."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}